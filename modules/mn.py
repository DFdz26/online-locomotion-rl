'''
Class: MN
created by: arthicha srisuchinnawong
Modified by: Daniel Fernandez
e-mail: dafer21@student.sdu.dk
date last modification: 5-01-23

Motor Neuron
'''


# ------------------- import modules ---------------------

# standard modules
import time, sys, os
from copy import deepcopy
import colorama 
colorama.init(autoreset=True)
from colorama import Fore
import os.path
import pickle

# math-related modules
import numpy as np # cpu array
import torch # cpu & gpu array
import torch as T
from torch.distributions import Normal, Categorical

# modular network
from modules.torchNet import torchNet

#plot
import matplotlib.pyplot as plt

# ------------------- configuration variables ---------------------

# ------------------- class MN ---------------------
'''
motor neurons: M[t] = 2.0*tanh(k W B[t])
'''

cacheFileName = "cache"
caccheExtension = ".pickle"

class MN(torchNet):	

	# -------------------- constructor -----------------------
	# (private)

	def __init__(self,hyperparams, load=0, outputgain=None, bias=False, device=None, dimensions=1, load_cache=True):

		# initialize network hyperparameter
		super().__init__(device)
		self.folder_cache = "cache_init_values"

		# device
		if device is not None:
			self.device = device
		elif torch.cuda.is_available():
			self.device = torch.device('cuda')
		else:
			self.device = torch.device('cpu')

		self.__n_state = hyperparams["n_state"]
		self.__n_out = hyperparams["n_out"]
		self.encoding = hyperparams["encoding"]
		self.__n_bias = 1 if bias else 0
		self.dimensions = dimensions

		if not os.path.exists(self.folder_cache):
			self.create_folder()

		self.full_cacheFilename = os.path.join(self.folder_cache, cacheFileName + "_" + self.encoding + caccheExtension)

		# initialize connection weight
		# self.W = self.zeros(self.__n_state+self.__n_bias,self.__n_out,grad=True)
		if os.path.exists(self.full_cacheFilename) and load_cache:
			self._load_cache_()
		else:
			self.W = 2*torch.rand(self.__n_state+self.__n_bias,self.__n_out, requires_grad=False, device=self.device) - 1
			
			if load_cache:
				self._create_cache_()

		# W_init = np.array([0.461050391,0.026585912,-0.063454144,-0.436189502,0.032500025,0.125215933,-0.053746615,-0.041209668,-0.128390566,0.070928775,-0.193970427,-0.046139546])
		# self.W = torch.FloatTensor(W_init).to(device=self.device)

		#self.load_weight(load)
		# self.Wn = self.zeros(dimensions, self.__n_state+self.__n_bias, self.__n_out)
		self.Wn = torch.zeros((dimensions,self.__n_state+self.__n_bias,self.__n_out), device=self.device)
		# self.Wn = self.zeros((dimensions, self.__n_state+self.__n_bias, self.__n_out))
		self.Wn = torch.add(self.W, self.Wn)

		self.reset()

		# normalize all joints -> output gain
		
		self.__output_gain = self.zeros(1,self.__n_out * dimensions) + 1.0 if outputgain is None else self.torch(outputgain)
		self.__output_gain = torch.reshape(self.__output_gain,(dimensions, self.__n_out))

	def create_folder(self):

		os.mkdir(self.folder_cache)

	def _load_cache_(self):
		print("loaded cache")
		with open(self.full_cacheFilename, 'rb') as f:
			self.W = pickle.load(f)
	
	def _create_cache_(self):
		
		print("stored cache")
		with open(self.full_cacheFilename, 'wb') as f:
			pickle.dump(self.W, f)
	
	def load_weight(self,load):
		if load == 1:
			'''
			#W_init = np.array([0.116192356,-0.140466675,0.028775813,-0.316917598,-0.178861663,-0.000824869,0.145588204,0.089445762,-0.081913367,-0.200662002,-0.157909706,-0.018792376,-0.038310137,-0.328516066,-0.045812525,0.066096894,-0.203897879,-0.008620108,-0.163143262,-0.192624509,0.215946048,-0.207753524,-0.025963251,-0.33088541,0.186106846,0.172960177,0.051174954,0.408280551,0.104044199,-0.032557897,-0.313274503,0.218402728,-0.135081515,0.225226402,0.380242974,-0.078804001,-0.067775123,0.035419721,0.150135845,0.381921738,-0.091516294,-0.062637895,0.108791344,-0.350752592,-0.061893716,-0.247389048,-0.115763098,0.1547831,0.170749232,-0.000856332,-0.367530286,-0.238307118,-0.045749173,0.021749079,0.116130605,0.151770085,-0.283171445,0.041184764,0.158718973,-0.028686902,-0.001621127,0.058967184,-0.269879133,-0.084427357,-0.024767106,-0.32723403,0.105792955,-0.020181105,0.012339802,0.012331083,-0.040340871,-0.158224791,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])
			#W_init = np.array([0.038980316,0.020546904,0.01657078,0.089707792,-0.006496058,0.062287822,-0.067595974,0.000221759,-0.005407453,-0.021466987,-0.017487582,0.001071588,-0.001150264,0.067104153,-0.018561998,-0.039921295,-0.037643205,-0.031410638,0.082440048,-0.014855318,-0.064495832,0.0102682,-0.023780346,0.007641856,0.036456801,0.051321603,-0.00900253,0.091194987,0.013425515,0.006036305,-0.052534841,-0.009974896,-0.042501718,0.021322176,0.010660799,0.009289988,0.052286576,0.008796366,0.02796988,-0.030730229,0.002047542,-0.021425733,0.093898691,0.026991352,0.027388709,-0.02893723,0.01485302,0.018480619,0.036780957,0.090030119,0.004824777,-0.125804931,0.006815111,0.039064709,-0.082572438,-0.014035437,0.012342892,0.090860918,0.058539748,-0.057984218,-0.049188077,0.012690543,-0.002998133,0.124410033,0.065302409,-0.002335902,-0.007890843,-0.030132813,-0.022149775,0.089581341,0.070731163,0.015989039,-4.51E-05,1.23E-05,2.44E-05,1.54E-05,-1.49E-05,-1.17E-05,4.14E-05,-5.04E-06,-1.38E-05,-2.61E-05,1.14E-05,1.97E-05,1.12E-05,9.44E-06,-1.61E-06,1.41E-05,1.22E-05,4.57E-06,5.09E-14,8.12E-14,1.62E-15,1.96E-15,-2.47E-14,-1.29E-13,-6.31E-14,-6.04E-14,2.16E-13,-1.76E-14,9.73E-14,8.90E-14,2.45E-13,-1.95E-13,-1.30E-13,-2.68E-14,6.65E-14,1.10E-13,-4.72E-13,8.99E-14,1.16E-13,-5.27E-13,-8.05E-14,-1.23E-13,5.87E-14,1.26E-13,3.93E-13,-3.74E-13,8.73E-14,-1.50E-13,-2.78E-13,9.22E-14,3.51E-13,5.98E-14,6.83E-14,3.55E-13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6.43E-11,-2.90E-11,-1.99E-11,1.03E-10,3.57E-11,-1.34E-10,1.66E-10,1.90E-11,-9.29E-11,1.37E-10,1.23E-10,8.05E-11,-1.30E-10,9.60E-11,1.79E-11,4.39E-11,-6.57E-11,-1.70E-11,2.26E-10,9.06E-11,-3.11E-11,-1.16E-10,3.02E-11,9.82E-11,2.79E-11,-1.83E-11,-1.26E-10,-1.00E-11,1.01E-10,2.13E-10,-1.33E-11,1.29E-10,-1.44E-10,-1.58E-11,5.28E-11,1.62E-11])
			
			# prelim slow forward down
			W_init = np.array([-0.21438463,-0.059280697,-0.02899076,-0.197632298,0.049631089,0.03268576,0.052675102,0.110804476,-0.140730038,0.065530188,0.03256109,0.032540727,-0.008710636,0.101791352,0.173325747,-0.234676063,-0.151691124,0.071750715,-0.043932341,0.033897348,-0.002643094,-0.14665705,0.05232057,0.018139899,-0.083623834,-0.003249293,-0.049461044,-0.07940305,0.034347724,0.124907233,-0.171763077,0.025558479,0.092725165,0.036985286,0.084470242,-0.045312725,0.008008209,0.066481851,-0.014202825,-0.294014275,-0.056666706,0.084962584,-0.021789415,0.057803307,-0.003854542,-0.035147376,0.017255431,-0.031542152,0.096362725,0.013241528,-0.14033407,-0.192574635,-0.039627656,-0.071866207,-0.080258191,0.036697723,-0.057427358,-0.23924385,-0.016815571,-0.153813109,-0.055898324,0.04747529,-0.082503401,0.055469777,0.202579796,-0.040758554,-0.111878,-0.049173348,0.023544811,0.025862377,0.005261757,-0.01515529,-0.213923231,0.115555927,0.065562062,-0.091515005,-0.137665391,-0.12857382,-0.179205716,0.02068729,0.02193726,-0.01338173,0.175219968,0.045297489,-0.287116677,-0.108184926,-0.099903516,-0.153833643,-0.105960563,-0.091336757,0.039936583,0.045707148,-0.153230801,-0.117020637,0.121377818,-0.083456948,0.101593129,0.119681232,0.119740687,0.064761594,0.195258662,-0.034279112,-0.330919415,-0.000234232,0.061583638,0.449207604,0.282690078,0.174117863,-0.182003066,0.023833241,-0.055298131,-0.083990656,0.076637477,-0.059493192,0.023315609,0.06429299,-0.046403103,0.096894428,0.003667978,0.121292964,-0.23408103,-0.010786636,0.027683796,-0.061894871,0.057618476,0.028343052,-0.09694922,0.145952404,-0.027960677,0.01425018,0.049564756,0.003881109,-0.088422604,-0.081968226,0.017062901,-0.149510637,0.177859932,0.136323616,-0.049699627,0.201869041,0.008879414,-0.090449348,0.147073686,0.022538895,1.28E-10,3.93E-11,-1.23E-10,-6.54E-10,-8.06E-11,-1.17E-10,-5.37E-10,1.48E-12,6.80E-11,-2.57E-10,2.38E-10,7.54E-11,-1.46E-10,-3.52E-11,-3.55E-10,-1.53E-10,7.06E-11,-9.45E-11,-1.36E-10,3.15E-10,4.89E-10,2.69E-10,-1.28E-10,1.87E-10,-6.79E-10,8.11E-11,4.14E-11,1.09E-09,-2.73E-10,3.54E-10,1.21E-11,2.42E-11,2.52E-10,-1.53E-10,4.86E-11,-3.50E-10,-0.108591221,-0.11532402,-0.118358545,-0.110238604,-0.117929235,-0.120405592,0.031945508,0.032252833,0.02867507,0.043309536,0.044405457,0.040352862])
			W_init = W_init[:180]

			#W_init = np.array([-0.045852154,-0.020947361,-0.085422121,-0.049157638,-0.013801459,-0.105019867,0.199282318,0.102448866,0.057494543,0.275143176,0.003791069,0.019737776,-0.196005747,-0.016146621,-0.036395665,-0.296266377,0.182707176,-0.077630259,-0.155850053,-0.018679852,0.203025341,-0.237270832,-0.093081713,-0.051542979,0.477938652,-0.011655927,-0.054316312,0.074822947,-0.12157318,-0.196232364,0.146783069,0.09066239,0.089967296,0.386400729,0.070385188,0.306726187,-0.04667367,-0.116021506,-0.014474875,-0.034131777,0.162165388,0.016438782,-0.133069307,-0.072182618,0.211692348,-0.226271987,-0.202432409,-0.181575432,0.24481149,0.018875364,0.060052816,0.106316596,0.148936138,-0.122303888,0.102369085,0.123458698,-0.061878178,0.261349231,0.041275483,0.063948467,0.159280211,0.164335772,-0.000348079,-0.217719436,0.013205543,-0.085208289,0.046809379,-0.169552669,-0.188790828,-0.147916287,-0.008593123,0.041054279,-5.23E-05,-5.90E-06,1.18E-05,-6.69E-05,7.86E-05,9.61E-06,-5.79E-05,-4.48E-05,0.000185701,-6.87E-05,8.92E-05,-0.000151785,-7.89E-05,3.94E-05,-2.73E-05,-4.63E-05,-8.80E-05,-2.69E-05,-0.000162407,-4.76E-05,-9.51E-05,-0.00010069,-4.45E-05,-6.50E-05,0.0001033,1.15E-05,6.17E-05,7.34E-05,9.92E-06,3.17E-05,-8.92E-05,-1.22E-05,-1.86E-05,0.00020908,5.49E-05,-3.59E-05,1.19E-09,-9.50E-10,7.07E-10,-6.20E-10,9.72E-10,-1.16E-11,4.99E-10,-1.52E-09,-8.02E-10,-6.05E-10,-2.13E-09,8.81E-10,2.80E-09,2.70E-10,3.30E-10,-2.58E-09,4.59E-10,1.40E-09,-2.33E-09,1.01E-10,-1.46E-09,3.05E-09,2.40E-09,3.04E-10,2.88E-10,-7.52E-10,7.98E-10,-1.06E-09,2.02E-10,3.24E-11,-7.66E-10,-2.55E-10,-1.20E-09,-4.00E-10,-1.66E-09,-1.08E-09,2.37E-09,1.72E-09,9.95E-10,8.27E-10,-5.37E-10,2.78E-10,2.90E-11,-4.41E-11,1.39E-09,-2.00E-09,6.70E-10,8.57E-10,2.77E-11,-1.35E-09,-5.53E-10,2.77E-09,5.08E-10,2.82E-10,-6.13E-10,-6.12E-11,-6.67E-10,4.97E-10,-4.48E-10,6.04E-10,-1.48E-09,-3.68E-10,8.55E-11,1.03E-09,6.79E-10,7.61E-10,-2.33E-09,1.47E-09,1.02E-09,1.23E-09,9.83E-10,-8.87E-10])
			#W_init = np.array([0.058716979,-0.127669126,0.064635336,0.065589383,0.105700739,-0.055956542,0.000950041,0.084133372,0.054446135,0.124429069,0.04520354,-0.049440693,0.051297456,0.058585394,-0.029181827,-0.071507514,-0.082859337,0.007249052,0.055801444,-0.0187057,-0.076181002,-0.097315036,-0.038484208,-0.079859652,0.009847885,0.041079875,-0.040048242,-0.142100275,-0.057481214,0.144486442,0.051243186,0.066237867,-0.06172188,0.157373667,0.004334551,0.03171334,-0.067223482,-0.027132399,-0.019598737,0.158042282,0.034667227,0.083924934,-0.073010907,0.027645962,0.029869076,0.05254598,-0.008475349,0.031530675,-0.030025855,-0.046064265,-0.02376483,-0.017976455,-0.0201688,-0.117151216,-0.002851095,0.10120409,0.057711255,-0.184352338,-0.083715715,0.076215245,0.04402161,0.025530322,0.079537839,0.035388838,0.050826401,-0.038346082,-0.127714857,-0.022066226,0.073395595,0.122514151,0.016119296,-0.012189019])
			'''
			# cpgrbf weight
			W_init = np.array([0.461050391,0.026585912,-0.063454144,-0.436189502,0.032500025,0.125215933,-0.053746615,-0.041209668,-0.128390566,0.070928775,-0.193970427,-0.046139546,-0.231163979,0.041387212,0.171054304,-0.221994817,-0.147135437,0.132841915,-0.139034465,-0.102867916,-0.202884033,-0.426688313,0.001075391,-0.250250041,0.125367656,-0.043413721,0.246181592,0.146319464,0.187765121,0.047159769,-0.065235756,-0.004891848,-0.050950374,-0.007819302,-0.114164524,-0.182072967,-0.411017478,0.107765749,-0.2021541,0.056735329,-0.093758941,-0.178499341,0.053473514,0.044496659,0.092114255,-0.213834256,-0.2262775,-0.15016979,0.106727161,0.359809101,-0.015076444,0.091582119,0.166188911,-0.115513474,-0.276746035,-0.150395215,-0.136127546,0.157676131,0.328430653,-0.068057343,0.510712743,-0.058537479,0.034455683,-0.113570966,-0.19850485,-0.044589594,-0.007740313,0.077424631,0.217545658,0.098569587,-0.002253419,-0.253627032])

			# avis weight
			#W_init = np.array([0.187981069,0.458965451,-0.355604768,-0.730624616,0.037821483,-0.127560526,0.330495864,0.131740525,-0.054032404,0.125971049,0.111693934,-0.309964776,-0.2724877,-0.281165838,-0.074229315,-0.118924968,-0.358999938,0.021825694,-0.48072806,-0.197486222,-0.217323378,-0.520836711,0.389445215,0.231248319,0.432570606,-0.132234976,0.018583935,0.327158183,0.048516568,-0.070191897,0.003323754,-0.214212596,-0.231122047,-0.177881986,-0.007128266,0.018915709,-0.754763544,-0.12393894,-0.373099059,0.315402418,0.098004229,-0.22142677,0.443576336,-0.224083871,0.015117905,0.036042631,0.152360603,-0.113363683,0.265721619,0.224658981,0.14111954,0.484894037,0.063701868,-0.23128356,-0.2811189,0.10178262,0.004174316,0.490046918,0.202703431,0.019813519,0.265407592,-0.05988596,-0.008609726,0.11214748,-0.082957707,-0.073204406,-0.198750079,0.28764239,0.159558848,-0.074207634,0.000376742,0.08772137])
			# W_init = np.repeat(np.array([0.4,-0.6,1.0,0.0]),3*4)


			W_init = torch.FloatTensor(W_init).to(self.device)
			W_init = torch.reshape(W_init,self.W.shape)
			
			if load == 2:
				W_init[:,[0,3,6,9,12,15]] *= -1

			with torch.no_grad():
				self.W += W_init

	def load_weights(self, nw, update_Wn=True):
		W_init = torch.FloatTensor(nw).to(self.device)
		print(W_init)
		print(self.W.shape)
		self.W = torch.reshape(W_init, self.W.shape)

		if update_Wn:
			self.Wn = torch.zeros((self.dimensions,self.__n_state+self.__n_bias,self.__n_out), device=self.device)
			self.Wn = torch.add(self.W, self.Wn)

	def get_w_arr_(self):
		return self.W.squeeze()

	# -------------------- set values -----------------------
	# (public)

	def apply_noise_tensor(self, noise):
		# print(f"noise {noise}")
		noise_a = torch.reshape(noise,self.Wn.shape)
		self.Wn = self.W + noise_a


	def apply_noise_np(self,noise):
		print(f"noise {noise}")
		noise_a = torch.FloatTensor(noise).to(self.device)
		noise_a = torch.reshape(noise_a,self.Wn.shape)
		self.Wn = self.W + noise_a

	def apply_noise(self,noise):
		self.Wn = self.W + noise

	# -------------------- handle functions -----------------------
	# (public)

	def reset(self):
		# reset connection
		pass

	def forward(self,x):
		if self.__n_bias > 0:
			shape = list(x.shape)
			shape[-1] = 1
			x1 = torch.cat([x,torch.ones(shape).to(self.device)],dim=-1)
		else:
			x1 = x
		outputs = 1 * torch.tanh( (x1@self.Wn)).reshape(self.dimensions, self.__n_out)
		return outputs




	
		




